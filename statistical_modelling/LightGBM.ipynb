{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kBxVi9FHk4Cz","executionInfo":{"status":"ok","timestamp":1701318185620,"user_tz":360,"elapsed":18666,"user":{"displayName":"Millennium Bismay","userId":"09399669580417612253"}},"outputId":"33845241-364e-40f8-968a-8c1ef9e0affd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qhKGiG0Lk7ut","executionInfo":{"status":"ok","timestamp":1701318185890,"user_tz":360,"elapsed":273,"user":{"displayName":"Millennium Bismay","userId":"09399669580417612253"}},"outputId":"9f4cb85a-4b96-474e-f9c1-c96a0e004a4b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["drive  sample_data\n"]}]},{"cell_type":"code","source":["%cd drive/Shareddrives/CS704_Project/data_processing"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HsExoU-plLeF","executionInfo":{"status":"ok","timestamp":1701318185997,"user_tz":360,"elapsed":115,"user":{"displayName":"Millennium Bismay","userId":"09399669580417612253"}},"outputId":"464d116b-aaca-42a9-ff22-3259e6b5e087"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Shareddrives/CS704_Project/data_processing\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","df = pd.read_csv(\"processed_data_3_majority.csv\")\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":724},"id":"u7vJzlGBlOEI","executionInfo":{"status":"ok","timestamp":1701318199132,"user_tz":360,"elapsed":4353,"user":{"displayName":"Millennium Bismay","userId":"09399669580417612253"}},"outputId":"9e4dd64b-38be-48d4-c970-31c438b6a807"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-8060f93470f0>:2: DtypeWarning: Columns (0,1,2,3,4,5,11,12,64,65) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(\"processed_data_3_majority.csv\")\n"]},{"output_type":"execute_result","data":{"text/plain":["                                               tweet target  \\\n","0  @POTUS Biden Blunders - 6 Month Update\\n\\nInfl...   True   \n","1  @S0SickRick @Stairmaster_ @6d6f636869 Not as m...   True   \n","2  THE SUPREME COURT is siding with super rich pr...   True   \n","3  @POTUS Biden Blunders\\n\\nBroken campaign promi...   True   \n","4  @OhComfy I agree. The confluence of events rig...   True   \n","\n","                  manual_keywords  \\\n","0  Americans, eviction moratorium   \n","1  Americans, eviction moratorium   \n","2  Americans, eviction moratorium   \n","3  Americans, eviction moratorium   \n","4  Americans, eviction moratorium   \n","\n","                                           statement 3_label_majority_answer  \\\n","0  End of eviction moratorium means millions of A...                   Agree   \n","1  End of eviction moratorium means millions of A...                   Agree   \n","2  End of eviction moratorium means millions of A...                   Agree   \n","3  End of eviction moratorium means millions of A...                   Agree   \n","4  End of eviction moratorium means millions of A...                   Agree   \n","\n","  followers_count  friends_count  favourites_count  statuses_count  \\\n","0          4262.0         3619.0           34945.0         16423.0   \n","1          1393.0         1621.0           31436.0         37184.0   \n","2             9.0           84.0             219.0          1184.0   \n","3          4262.0         3619.0           34945.0         16423.0   \n","4            70.0          166.0           15282.0          2194.0   \n","\n","   listed_count  ...  dots exclamation questions  ampersand  capitals  digits  \\\n","0          44.0  ...   5.0         0.0       1.0        0.0      33.0     3.0   \n","1          64.0  ...   1.0         0.0       0.0        0.0      14.0     0.0   \n","2           0.0  ...   0.0         0.0       0.0        0.0       3.0     0.0   \n","3          44.0  ...   3.0         0.0       0.0        1.0       6.0     8.0   \n","4           0.0  ...   3.0         0.0       1.0        0.0      11.0     3.0   \n","\n","   long_word_freq  short_word_freq  \\\n","0             5.0             19.0   \n","1             2.0             34.0   \n","2             4.0             10.0   \n","3             1.0             30.0   \n","4             2.0             19.0   \n","\n","                                       cleaned_tweet  Truthfulness  \n","0  Biden Blunders  6 Month Update  Inflation Delt...          True  \n","1  Not as many people are literally starving and ...          True  \n","2  THE SUPREME COURT is siding with super rich pr...          True  \n","3  Biden Blunders  Broken campaign promises Infla...          True  \n","4  I agree The confluence of events right now is ...          True  \n","\n","[5 rows x 66 columns]"],"text/html":["\n","  <div id=\"df-55f20eb1-fe19-49be-b784-40a49ed120eb\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet</th>\n","      <th>target</th>\n","      <th>manual_keywords</th>\n","      <th>statement</th>\n","      <th>3_label_majority_answer</th>\n","      <th>followers_count</th>\n","      <th>friends_count</th>\n","      <th>favourites_count</th>\n","      <th>statuses_count</th>\n","      <th>listed_count</th>\n","      <th>...</th>\n","      <th>dots</th>\n","      <th>exclamation</th>\n","      <th>questions</th>\n","      <th>ampersand</th>\n","      <th>capitals</th>\n","      <th>digits</th>\n","      <th>long_word_freq</th>\n","      <th>short_word_freq</th>\n","      <th>cleaned_tweet</th>\n","      <th>Truthfulness</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>@POTUS Biden Blunders - 6 Month Update\\n\\nInfl...</td>\n","      <td>True</td>\n","      <td>Americans, eviction moratorium</td>\n","      <td>End of eviction moratorium means millions of A...</td>\n","      <td>Agree</td>\n","      <td>4262.0</td>\n","      <td>3619.0</td>\n","      <td>34945.0</td>\n","      <td>16423.0</td>\n","      <td>44.0</td>\n","      <td>...</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>33.0</td>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>19.0</td>\n","      <td>Biden Blunders  6 Month Update  Inflation Delt...</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>@S0SickRick @Stairmaster_ @6d6f636869 Not as m...</td>\n","      <td>True</td>\n","      <td>Americans, eviction moratorium</td>\n","      <td>End of eviction moratorium means millions of A...</td>\n","      <td>Agree</td>\n","      <td>1393.0</td>\n","      <td>1621.0</td>\n","      <td>31436.0</td>\n","      <td>37184.0</td>\n","      <td>64.0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>14.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>34.0</td>\n","      <td>Not as many people are literally starving and ...</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>THE SUPREME COURT is siding with super rich pr...</td>\n","      <td>True</td>\n","      <td>Americans, eviction moratorium</td>\n","      <td>End of eviction moratorium means millions of A...</td>\n","      <td>Agree</td>\n","      <td>9.0</td>\n","      <td>84.0</td>\n","      <td>219.0</td>\n","      <td>1184.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>10.0</td>\n","      <td>THE SUPREME COURT is siding with super rich pr...</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>@POTUS Biden Blunders\\n\\nBroken campaign promi...</td>\n","      <td>True</td>\n","      <td>Americans, eviction moratorium</td>\n","      <td>End of eviction moratorium means millions of A...</td>\n","      <td>Agree</td>\n","      <td>4262.0</td>\n","      <td>3619.0</td>\n","      <td>34945.0</td>\n","      <td>16423.0</td>\n","      <td>44.0</td>\n","      <td>...</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>6.0</td>\n","      <td>8.0</td>\n","      <td>1.0</td>\n","      <td>30.0</td>\n","      <td>Biden Blunders  Broken campaign promises Infla...</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>@OhComfy I agree. The confluence of events rig...</td>\n","      <td>True</td>\n","      <td>Americans, eviction moratorium</td>\n","      <td>End of eviction moratorium means millions of A...</td>\n","      <td>Agree</td>\n","      <td>70.0</td>\n","      <td>166.0</td>\n","      <td>15282.0</td>\n","      <td>2194.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>19.0</td>\n","      <td>I agree The confluence of events right now is ...</td>\n","      <td>True</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 66 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55f20eb1-fe19-49be-b784-40a49ed120eb')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-55f20eb1-fe19-49be-b784-40a49ed120eb button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-55f20eb1-fe19-49be-b784-40a49ed120eb');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-98c04714-2b83-496f-82ae-94489f6c8c13\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-98c04714-2b83-496f-82ae-94489f6c8c13')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-98c04714-2b83-496f-82ae-94489f6c8c13 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":[],"metadata":{"id":"Pt2fiRjzd8E-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = df[df['Truthfulness'].isin([True, False])]\n","X = df.select_dtypes(include='number').assign(cleaned_tweet=df['cleaned_tweet'])\n","y = df['Truthfulness']"],"metadata":{"id":"ba5i3CS0lPwG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)"],"metadata":{"id":"7ysZXTyXlSqE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train_1 = X_train.drop('cleaned_tweet', axis=1)\n","y_train_1 = y_train.map({True: 1, False: 0})\n","\n","X_val_1 = X_temp.drop('cleaned_tweet', axis=1)\n","y_val_numeric = y_temp.map({True: 1, False: 0})"],"metadata":{"id":"cXcFJ5iGlUuk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import lightgbm as lgb\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","\n","num_leaves_list = [31]\n","n_estimators_list = list(range(800, 1501, 100))\n","lr_list = [0.1]\n","boosting_type_list = ['gbdt']\n","\n","for num_leaves in num_leaves_list:\n","  for n_estimators in n_estimators_list:\n","    for lr in lr_list:\n","      for boosting_type in boosting_type_list:\n","        print(\"num_leaves: {} --- n_estimators: {} --- lr: {} --- boosting_type: {}\".format(num_leaves, n_estimators, lr, boosting_type))\n","        # Define parameters for LightGBM\n","        params = {\n","            'objective': 'binary',\n","            'metric': 'binary_error',  # You can change the metric as needed\n","            'boosting_type': boosting_type,\n","            'num_leaves': num_leaves,\n","            'learning_rate': lr,\n","            'feature_fraction': 0.9,\n","            'n_estimators': n_estimators,\n","            'seed': 42,\n","        }\n","\n","        # Create a LightGBM dataset\n","        train_data = lgb.Dataset(X_train_1, label=y_train_1)\n","        test_data = lgb.Dataset(X_val_1, label=y_val_numeric, reference=train_data)\n","\n","        # Train the model\n","        num_round = 100  # Number of boosting rounds\n","        bst = lgb.train(params, train_data, num_round, valid_sets=[test_data])\n","\n","        # Make predictions on the test set\n","        y_pred_prob = bst.predict(X_val_1, num_iteration=bst.best_iteration)\n","        y_pred = (y_pred_prob > 0.5).astype(int)\n","\n","        # Calculate metrics\n","        accuracy = accuracy_score(y_val_numeric, y_pred)\n","        f1 = f1_score(y_val_numeric, y_pred)\n","        precision = precision_score(y_val_numeric, y_pred)\n","        recall = recall_score(y_val_numeric, y_pred)\n","\n","        print(f\"Accuracy: {accuracy:.2f}\")\n","        print(f\"F1 Score: {f1:.2f}\")\n","        print(f\"Precision: {precision:.2f}\")\n","        print(f\"Recall: {recall:.2f}\")\n","        print(\"\\n\" + \"=\"*50 + \"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4zEPNuCulXir","executionInfo":{"status":"ok","timestamp":1701314812533,"user_tz":360,"elapsed":191569,"user":{"displayName":"Anushka Garg","userId":"04466625439616717114"}},"outputId":"d4a66236-14bb-4d0b-a6e6-5d442df195d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["num_leaves: 31 --- n_estimators: 800 --- lr: 0.1 --- boosting_type: gbdt\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] Number of positive: 47302, number of negative: 45680\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.114435 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4019\n","[LightGBM] [Info] Number of data points in the train set: 92982, number of used features: 55\n","[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508722 -> initscore=0.034892\n","[LightGBM] [Info] Start training from score 0.034892\n","Accuracy: 0.70\n","F1 Score: 0.70\n","Precision: 0.71\n","Recall: 0.68\n","\n","==================================================\n","\n","num_leaves: 31 --- n_estimators: 900 --- lr: 0.1 --- boosting_type: gbdt\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] Number of positive: 47302, number of negative: 45680\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.286747 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4019\n","[LightGBM] [Info] Number of data points in the train set: 92982, number of used features: 55\n","[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508722 -> initscore=0.034892\n","[LightGBM] [Info] Start training from score 0.034892\n","Accuracy: 0.70\n","F1 Score: 0.70\n","Precision: 0.71\n","Recall: 0.69\n","\n","==================================================\n","\n","num_leaves: 31 --- n_estimators: 1000 --- lr: 0.1 --- boosting_type: gbdt\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] Number of positive: 47302, number of negative: 45680\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029719 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4019\n","[LightGBM] [Info] Number of data points in the train set: 92982, number of used features: 55\n","[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508722 -> initscore=0.034892\n","[LightGBM] [Info] Start training from score 0.034892\n","Accuracy: 0.70\n","F1 Score: 0.70\n","Precision: 0.71\n","Recall: 0.69\n","\n","==================================================\n","\n","num_leaves: 31 --- n_estimators: 1100 --- lr: 0.1 --- boosting_type: gbdt\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] Number of positive: 47302, number of negative: 45680\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029539 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4019\n","[LightGBM] [Info] Number of data points in the train set: 92982, number of used features: 55\n","[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508722 -> initscore=0.034892\n","[LightGBM] [Info] Start training from score 0.034892\n","Accuracy: 0.69\n","F1 Score: 0.70\n","Precision: 0.71\n","Recall: 0.68\n","\n","==================================================\n","\n","num_leaves: 31 --- n_estimators: 1200 --- lr: 0.1 --- boosting_type: gbdt\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] Number of positive: 47302, number of negative: 45680\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.360444 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4019\n","[LightGBM] [Info] Number of data points in the train set: 92982, number of used features: 55\n","[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508722 -> initscore=0.034892\n","[LightGBM] [Info] Start training from score 0.034892\n","Accuracy: 0.69\n","F1 Score: 0.70\n","Precision: 0.71\n","Recall: 0.68\n","\n","==================================================\n","\n","num_leaves: 31 --- n_estimators: 1300 --- lr: 0.1 --- boosting_type: gbdt\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] Number of positive: 47302, number of negative: 45680\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041255 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4019\n","[LightGBM] [Info] Number of data points in the train set: 92982, number of used features: 55\n","[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508722 -> initscore=0.034892\n","[LightGBM] [Info] Start training from score 0.034892\n","Accuracy: 0.70\n","F1 Score: 0.70\n","Precision: 0.71\n","Recall: 0.69\n","\n","==================================================\n","\n","num_leaves: 31 --- n_estimators: 1400 --- lr: 0.1 --- boosting_type: gbdt\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] Number of positive: 47302, number of negative: 45680\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028908 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4019\n","[LightGBM] [Info] Number of data points in the train set: 92982, number of used features: 55\n","[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508722 -> initscore=0.034892\n","[LightGBM] [Info] Start training from score 0.034892\n","Accuracy: 0.70\n","F1 Score: 0.70\n","Precision: 0.71\n","Recall: 0.69\n","\n","==================================================\n","\n","num_leaves: 31 --- n_estimators: 1500 --- lr: 0.1 --- boosting_type: gbdt\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] Number of positive: 47302, number of negative: 45680\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.427545 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4019\n","[LightGBM] [Info] Number of data points in the train set: 92982, number of used features: 55\n","[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508722 -> initscore=0.034892\n","[LightGBM] [Info] Start training from score 0.034892\n","Accuracy: 0.70\n","F1 Score: 0.70\n","Precision: 0.71\n","Recall: 0.69\n","\n","==================================================\n","\n"]}]},{"cell_type":"code","source":["num_leaves: 50 --- n_estimators: 400 --- lr: 0.1 --- boosting_type: gbdt\n","/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n","[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] Number of positive: 47302, number of negative: 45680\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036235 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4019\n","[LightGBM] [Info] Number of data points in the train set: 92982, number of used features: 55\n","[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508722 -> initscore=0.034892\n","[LightGBM] [Info] Start training from score 0.034892\n","Accuracy: 0.70\n","F1 Score: 0.70\n","Precision: 0.71\n","Recall: 0.69\n"],"metadata":{"id":"BL8ybmNXmZ82"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Best model"],"metadata":{"id":"s2wesjJgWnzH"}},{"cell_type":"code","source":["import pandas as pd\n","import lightgbm as lgb\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","\n","num_leaves_list = [50]\n","n_estimators_list = [400]\n","lr_list = [0.1]\n","boosting_type_list = ['gbdt']\n","\n","for num_leaves in num_leaves_list:\n","  for n_estimators in n_estimators_list:\n","    for lr in lr_list:\n","      for boosting_type in boosting_type_list:\n","        print(\"num_leaves: {} --- n_estimators: {} --- lr: {} --- boosting_type: {}\".format(num_leaves, n_estimators, lr, boosting_type))\n","        # Define parameters for LightGBM\n","        params = {\n","            'objective': 'binary',\n","            'metric': 'binary_error',  # You can change the metric as needed\n","            'boosting_type': boosting_type,\n","            'num_leaves': num_leaves,\n","            'learning_rate': lr,\n","            'feature_fraction': 0.9,\n","            'n_estimators': n_estimators,\n","            'seed': 42,\n","        }\n","\n","        # Create a LightGBM dataset\n","        train_data = lgb.Dataset(X_train_1, label=y_train_1)\n","        test_data = lgb.Dataset(X_val_1, label=y_val_numeric, reference=train_data)\n","\n","        # Train the model\n","        num_round = 100  # Number of boosting rounds\n","        bst = lgb.train(params, train_data, num_round, valid_sets=[test_data])\n","\n","        # Make predictions on the test set\n","        y_pred_prob = bst.predict(X_val_1, num_iteration=bst.best_iteration)\n","        y_pred = (y_pred_prob > 0.5).astype(int)\n","\n","        # Calculate metrics\n","        accuracy = accuracy_score(y_val_numeric, y_pred)\n","        f1 = f1_score(y_val_numeric, y_pred)\n","        precision = precision_score(y_val_numeric, y_pred)\n","        recall = recall_score(y_val_numeric, y_pred)\n","\n","        print(f\"Accuracy: {accuracy:.2f}\")\n","        print(f\"F1 Score: {f1:.2f}\")\n","        print(f\"Precision: {precision:.2f}\")\n","        print(f\"Recall: {recall:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AEWo1X1gWqiu","executionInfo":{"status":"ok","timestamp":1701316495090,"user_tz":360,"elapsed":18112,"user":{"displayName":"Anushka Garg","userId":"04466625439616717114"}},"outputId":"df172a69-c80a-40c8-e1ef-9e6e99413353"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["num_leaves: 50 --- n_estimators: 400 --- lr: 0.1 --- boosting_type: gbdt\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] Number of positive: 47302, number of negative: 45680\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.155861 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 4019\n","[LightGBM] [Info] Number of data points in the train set: 92982, number of used features: 55\n","[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508722 -> initscore=0.034892\n","[LightGBM] [Info] Start training from score 0.034892\n","Accuracy: 0.70\n","F1 Score: 0.70\n","Precision: 0.71\n","Recall: 0.69\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import lightgbm as lgb\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","\n","# Assuming X_train_1, y_train_1, X_val_1, y_val_numeric are defined before this code\n","\n","num_leaves_list = [50]\n","n_estimators_list = [400]\n","lr_list = [0.1]\n","boosting_type_list = ['gbdt']\n","\n","for num_leaves in num_leaves_list:\n","    for n_estimators in n_estimators_list:\n","        for lr in lr_list:\n","            for boosting_type in boosting_type_list:\n","                print(\"num_leaves: {} --- n_estimators: {} --- lr: {} --- boosting_type: {}\".format(num_leaves, n_estimators, lr, boosting_type))\n","\n","                # Define parameters for LightGBM\n","                params = {\n","                    'objective': 'binary',\n","                    'metric': 'binary_error',  # You can change the metric as needed\n","                    'boosting_type': boosting_type,\n","                    'num_leaves': num_leaves,\n","                    'learning_rate': lr,\n","                    'feature_fraction': 0.9,\n","                    'n_estimators': n_estimators,\n","                    'seed': 42,\n","                }\n","\n","                # Create a LightGBM dataset\n","                train_data = lgb.Dataset(X_train_1, label=y_train_1)\n","                test_data = lgb.Dataset(X_val_1, label=y_val_numeric, reference=train_data)\n","\n","                # Train the model\n","                num_round = 100  # Number of boosting rounds\n","                bst = lgb.train(params, train_data, num_round, valid_sets=[test_data])\n","\n","                model_filename = f\"lightgbm_model_num_leaves_{num_leaves}_n_estimators_{n_estimators}_lr_{lr}_{boosting_type}.h5\"\n","                bst.save_model(model_filename)\n","\n","                # Get feature importance and print in order of highest to lowest\n","                feature_importance = bst.feature_importance(importance_type='split')  # 'split' or 'gain' depending on your preference\n","                feature_names = X_train_1.columns\n","\n","                # Create a DataFrame to organize feature names and their importance\n","                feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n","\n","                # Sort the DataFrame by importance in descending order\n","                feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n","\n","                # Print the sorted feature importance\n","                print(\"Feature Importance:\")\n","                print(feature_importance_df)\n","\n","                # Make predictions on the test set\n","                y_pred_prob = bst.predict(X_val_1, num_iteration=bst.best_iteration)\n","                y_pred = (y_pred_prob > 0.5).astype(int)\n","\n","                # Calculate metrics\n","                accuracy = accuracy_score(y_val_numeric, y_pred)\n","                f1 = f1_score(y_val_numeric, y_pred)\n","                precision = precision_score(y_val_numeric, y_pred)\n","                recall = recall_score(y_val_numeric, y_pred)\n","\n","                print(f\"Accuracy: {accuracy:.2f}\")\n","                print(f\"F1 Score: {f1:.2f}\")\n","                print(f\"Precision: {precision:.2f}\")\n","                print(f\"Recall: {recall:.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HqnvJDBaXOz3","executionInfo":{"status":"ok","timestamp":1701317618540,"user_tz":360,"elapsed":16267,"user":{"displayName":"Anushka Garg","userId":"04466625439616717114"}},"outputId":"b98435a8-0461-4a3e-b4ef-bd66950d1424"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["num_leaves: 50 --- n_estimators: 400 --- lr: 0.1 --- boosting_type: gbdt\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n","  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"]},{"output_type":"stream","name":"stdout","text":["[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] Number of positive: 47302, number of negative: 45680\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.182882 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 4019\n","[LightGBM] [Info] Number of data points in the train set: 92982, number of used features: 55\n","[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508722 -> initscore=0.034892\n","[LightGBM] [Info] Start training from score 0.034892\n","Feature Importance:\n","                   Feature  Importance\n","38     Average word length        1190\n","1         favourites_count        1122\n","2           statuses_count        1120\n","6                     cred        1023\n","0            friends_count         972\n","7      normalize_influence         906\n","35              Word count         809\n","52                capitals         731\n","3             listed_count         666\n","55         short_word_freq         633\n","53                  digits         564\n","36         Max word length         542\n","40              past_verbs         512\n","41              adjectives         474\n","20       PERSON_percentage         460\n","43             adpositions         459\n","19          GPE_percentage         436\n","17          ORG_percentage         417\n","39           present_verbs         379\n","22         DATE_percentage         379\n","48                    dots         354\n","23     CARDINAL_percentage         353\n","18         NORP_percentage         327\n","16             total_count         326\n","42                 adverbs         325\n","54          long_word_freq         321\n","44                pronouns         316\n","12              favourites         306\n","8                 mentions         289\n","24      PERCENT_percentage         256\n","47            conjunctions         252\n","45                     TOs         201\n","15            unique_count         189\n","21        MONEY_percentage         181\n","10                 replies         169\n","11                retweets         153\n","14                    URLs         153\n","37         Min word length         149\n","49             exclamation         144\n","50               questions         132\n","31          LOC_percentage          95\n","51               ampersand          93\n","25      ORDINAL_percentage          82\n","32  WORK_OF_ART_percentage          81\n","33     QUANTITY_percentage          72\n","13                hashtags          71\n","46             determiners          66\n","30         TIME_percentage          65\n","28      PRODUCT_percentage          59\n","27          LAW_percentage          53\n","9                   quotes          44\n","29        EVENT_percentage          42\n","26          FAC_percentage          39\n","34     LANGUAGE_percentage          38\n","5           BotScoreBinary          10\n","4                following           0\n","Accuracy: 0.70\n","F1 Score: 0.70\n","Precision: 0.71\n","Recall: 0.69\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"nXb3G6s-YPz0"},"execution_count":null,"outputs":[]}]}